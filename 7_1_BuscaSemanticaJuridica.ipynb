{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "id": "B-I26nmPNb7B",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Pinecone as PineconeVectorStore\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pinecone import Pinecone\n",
    "import yaml\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "os.environ['PINECONE_API_KEY'] = config['PINECONE_API_KEY']\n",
    "os.environ['OPENAI_API_KEY'] = config['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Busca Semântica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file_path = 'documentos.zip'\n",
    "extracted_folder_path = 'docs'\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_folder_path)\n",
    "\n",
    "documents = []\n",
    "for filename in os.listdir(extracted_folder_path):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        file_path = os.path.join(extracted_folder_path, filename)\n",
    "        loader = PyMuPDFLoader(file_path)\n",
    "        documents.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  \n",
    "    chunk_overlap=100,\n",
    "    length_function=len\n",
    ")\n",
    "chunks = text_splitter.create_documents([doc.page_content for doc in documents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'llm' \n",
    "vector_store = PineconeVectorStore.from_documents(chunks, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = '''Responda apenas com base no input fornecido. Qual o número do processo que trata de Violação\n",
    "de normas ambientais pela Empresa de Construção?'''\n",
    "query_2 = 'Responda apenas com base no input fornecido. Qual foi a decisão no caso de fraude financeira?'\n",
    "query_3 = 'Responda apenas com base no input fornecido. Quais foram as alegações no caso de negligência médica?'\n",
    "query_4 = 'Responda apenas com base no input fornecido. Quais foram as alegações no caso de Número do Processo: 822162' #disputa contratual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RetrievalQA.from_chain_type(llm=llm, chain_type='stuff', retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combine_documents_chain=StuffDocumentsChain(llm_chain=LLMChain(prompt=ChatPromptTemplate(input_variables=['context', 'question'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template=\"Use the following pieces of context to answer the user's question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n{context}\")), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='{question}'))]), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x758f0e5bd550>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x758f0e537230>, temperature=0.2, openai_api_key=SecretStr('**********'), openai_proxy='')), document_variable_name='context') retriever=VectorStoreRetriever(tags=['Pinecone', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.pinecone.Pinecone object at 0x758f219b9580>, search_kwargs={'k': 3})\n"
     ]
    }
   ],
   "source": [
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_1 = chain.invoke(query_1)\n",
    "answer_2 = chain.invoke(query_2)\n",
    "answer_3 = chain.invoke(query_3)\n",
    "answer_4 = chain.invoke(query_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pergunta:  Responda apenas com base no input fornecido. Qual o número do processo que trata de Violação\n",
      "de normas ambientais pela Empresa de Construção?\n",
      "Resultado:  O número do processo que trata da Violação de normas ambientais pela Empresa de Construção é 175543. \n",
      "\n",
      "Pergunta:  Responda apenas com base no input fornecido. Qual foi a decisão no caso de fraude financeira?\n",
      "Resultado:  A decisão no caso de fraude financeira envolvendo João Almeida foi uma sentença de dez anos de prisão e a restituição de $1,000,000 ao Banco Nacional. \n",
      "\n",
      "Pergunta:  Responda apenas com base no input fornecido. Quais foram as alegações no caso de negligência médica?\n",
      "Resultado:  Ana Oliveira alegou que Dr. Pedro Sousa não realizou os procedimentos médicos com o cuidado necessário, resultando em complicações graves. Tratamentos realizados incluíram uma cirurgia mal-sucedida que levou a infecções adicionais. Depoimentos de especialistas médicos apoiaram as alegações de negligência. \n",
      "\n",
      "Pergunta:  Responda apenas com base no input fornecido. Quais foram as alegações no caso de Número do Processo: 822162\n",
      "Resultado:  As alegações no caso de Número do Processo 822162 foram de quebra de contrato pela Empresa W, que afirmou que o Fornecedor K não entregou os materiais conforme os termos acordados.\n"
     ]
    }
   ],
   "source": [
    "print('Pergunta: ',answer_1['query'])\n",
    "print('Resultado: ',answer_1['result'],'\\n')\n",
    "#---\n",
    "print('Pergunta: ',answer_2['query'])\n",
    "print('Resultado: ',answer_2['result'],'\\n')\n",
    "#---\n",
    "print('Pergunta: ',answer_3['query'])\n",
    "print('Resultado: ',answer_3['result'],'\\n')\n",
    "#---\n",
    "print('Pergunta: ',answer_4['query'])\n",
    "print('Resultado: ',answer_4['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
